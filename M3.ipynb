{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c9794378",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.layers import Dense, InputLayer, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing import image\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from glob import glob\n",
    "import math,os\n",
    "import statistics as s\n",
    "import csv\n",
    "\n",
    "stat=0\n",
    "size=0\n",
    "abuse=0\n",
    "arrest=0\n",
    "assault=0\n",
    "burglary=0\n",
    "explosion=0\n",
    "fighting=0\n",
    "normal=0\n",
    "roadaccident=0\n",
    "robbery=0\n",
    "shooting=0\n",
    "shoplifting=0\n",
    "stealing=0\n",
    "vandalism=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "11da9aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models    \n",
    "base_model = VGG16(weights='imagenet', include_top=False)\n",
    "model = models.load_model('weight.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ebebf0d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# creating two lists to store predicted and actual tags\n",
    "predict = []\n",
    "\n",
    "cc=0\n",
    "count=0\n",
    "videof=glob(\"uploads/*.mp4\")\n",
    "cap= cv2.VideoCapture(videof[0])\n",
    "i=0\n",
    "count=0\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if ret == False:\n",
    "        break\n",
    "    cv2.imwrite('temp/_frame'+str(i)+'.jpg',frame)\n",
    "    count += 30 # i.e. at 30 fps, this advances one second\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, count)\n",
    "    i+=1\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# reading all the frames from temp folder\n",
    "images = glob(\"temp/*.jpg\")\n",
    "\n",
    "prediction_images = []\n",
    "for i in range(len(images)):\n",
    "    img = image.load_img(images[i], target_size=(224,224,3))\n",
    "    img = image.img_to_array(img)\n",
    "    img = img/255\n",
    "    prediction_images.append(img)\n",
    "\n",
    "\n",
    "\n",
    "# converting all the frames for a test video into numpy array\n",
    "prediction_images = np.array(prediction_images)\n",
    "# extracting features using pre-trained model\n",
    "\n",
    "prediction_images = base_model.predict(prediction_images)\n",
    "\n",
    "# converting features in one dimensional array\n",
    "prediction_images = prediction_images.reshape(prediction_images.shape[0], 7*7*512)\n",
    "# predicting tags for each array\n",
    "\n",
    "pre=model.predict(prediction_images)\n",
    "prediction = np.argmax(pre,axis=1)\n",
    "print(prediction)\n",
    "#print(s.mode(prediction))\n",
    "# appending the mode of predictions in predict list to assign the tag to the video\n",
    "\n",
    "# appending the actual tag of the video\n",
    "#print(videoFile.split('_')[0].split('0')[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a31627c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "suspicious\n"
     ]
    }
   ],
   "source": [
    "size=len(prediction)\n",
    "for a in prediction:\n",
    "    if a==0:\n",
    "        abuse=abuse+1\n",
    "    if a==1:\n",
    "        arrest=arrest+1\n",
    "    if a==2:\n",
    "        assault=assault+1\n",
    "    if a==3:\n",
    "        burglary=burglary+1\n",
    "    if a==4:\n",
    "        explosion=explosion+1\n",
    "    if a==5:\n",
    "        fighting=fighting+1\n",
    "    if a==6:\n",
    "        normal=normal+1\n",
    "    if a==7:\n",
    "        roadaccident=roadaccident+1\n",
    "    if a==8:\n",
    "        robbery=robbery+1\n",
    "    if a==9:\n",
    "        shooting=shooting+1\n",
    "    if a==10:\n",
    "        shoplifting=shoplifting+1\n",
    "    if a==11:\n",
    "        stealing=stealing+1\n",
    "    if a==12:\n",
    "        vandalism=vandalism+1\n",
    "        \n",
    "        \n",
    "if (abuse+arrest+assault+burglary+explosion+fighting+roadaccident+robbery+shooting+shoplifting+stealing+vandalism)>normal:\n",
    "    print(\"suspicious\")\n",
    "    stat=1\n",
    "    \n",
    "else:\n",
    "    print(\"normal\")\n",
    "    stat=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "34d3742f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"stream.csv\",'w') as f:\n",
    "    csv.writer(f).writerow([stat,size,abuse,arrest,assault,burglary,explosion,fighting,normal,roadaccident,robbery,shooting,shoplifting,stealing,vandalism])\n",
    "    f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "91555e203e11ede8496fb03363e909d37d72bb051c20872b508296bfc889c327"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
